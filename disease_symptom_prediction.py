# -*- coding: utf-8 -*-
"""Disease Symptom Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_-U3kvC5FmV7M7RG_u6gGF389yK2MP5t

# Disease Symptom Prediction

# Introduction

This project aims to build a machine learning model capable of predicting possible diseases based on a set of symptoms provided by the user. By analyzing the relationship between symptoms and their corresponding diagnoses, the model assists in early detection and decision making for medical professionals and patients.
The approach involves data preprocessing, handling missing values, feature encoding, and applying classification algorithms such as Random Forest to achieve accurate predictions. Special attention is given to model evaluation using metrics like accuracy, precision, recall, and F1-score to ensure reliable results.

Data Source: https://www.kaggle.com/datasets/itachi9604/disease-symptom-description-dataset/data

**Amar Ahmed**

**Data Scientist** | **Machine Learning Engineer**  | **Computer Vision Researcher**

# Installing
"""

!pip install ydata_profiling # EDA

!pip install gradio

"""# Load Data & Import Libraries"""

import kagglehub
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import gradio as gr
import joblib
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score, cross_val_predict
from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score
from ydata_profiling import ProfileReport
from wordcloud import WordCloud

# Download latest version
path = kagglehub.dataset_download("itachi9604/disease-symptom-description-dataset")
print("Path to dataset files:", path)
# Read Data
Data = pd.read_csv(path + "/dataset.csv")
Data

# Data Overview
display("Data size:", Data.shape)
print('--------------------------------------------')
display("\n columns:", Data.columns.tolist())
print('--------------------------------------------')
display("\n Data type:", Data.dtypes)
print('--------------------------------------------')

Data.info()

Data.describe(include='object')

display(Data.isnull().sum())

plt.figure(figsize=(11, 5))
sns.heatmap(Data.isnull(), cbar=False, cmap='viridis')
plt.title('Missing Values Heatmap')
plt.show()
plt.savefig('Missing_Heatmap DSP.png')

Data.duplicated().sum()

Data.sample(10)

Data.columns

Data['Disease'].value_counts()

Data['Symptom_1'].value_counts()

Data['Symptom_2'].value_counts()

Data[Data['Disease'] == Data['Disease'].max()]['Symptom_1']

Data[Data['Disease'] == Data['Disease'].min()]['Symptom_1']

"""# **Analysis**

"""

plt.subplots(figsize=(8, 8))
df_2dhist = pd.DataFrame({
    x_label: grp['Symptom_15'].value_counts()
    for x_label, grp in Data.groupby('Symptom_14')
})
sns.heatmap(df_2dhist, cmap='viridis')
plt.xlabel('Symptom_14')
_ = plt.ylabel('Symptom_15')

Data.groupby('Symptom_14').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))
plt.gca().spines[['top', 'right',]].set_visible(False)

plt.subplots(figsize=(8, 8))
df_2dhist = pd.DataFrame({
    x_label: grp['Symptom_17'].value_counts()
    for x_label, grp in Data.groupby('Symptom_16')
})
sns.heatmap(df_2dhist, cmap='viridis')
plt.xlabel('Symptom_16')
_ = plt.ylabel('Symptom_17')

"""# Full Report


"""

# ProfileReport(Data, title="Profiling Report")

"""# Data Cleaning & Preprocessing"""

def colect_columns(df):
    Symptom_col = df.columns.tolist()[1:] # all columns except first
    df['Symptom'] = df[Symptom_col].apply(lambda row: ','.join(row.values.astype(str)), axis=1)
    df = df[['Disease', 'Symptom']] # only
    df = df.drop_duplicates()
    return df

Data_colect = colect_columns(Data)

Data_colect

Data_colect.info()

Data_colect.isnull().sum()

plt.figure(figsize=(11, 5))
sns.heatmap(Data_colect.isnull(), cbar=False, cmap='viridis')
plt.title('Missing Values Heatmap')
plt.show()

plt.figure(figsize=(8, 8))
plt.pie(Data_colect['Disease'].value_counts(), labels=Data_colect['Disease'].value_counts().index, autopct='%1.1f%%')
plt.title('Disease Distribution')
plt.show()
plt.savefig('Disease_Distribution DSP.png')

cloud = WordCloud(background_color='white', width=800, height=400)
cloud = cloud.generate_from_frequencies(Data_colect['Disease'].value_counts())
plt.figure(figsize=(10, 5))
plt.imshow(cloud, interpolation='bilinear')
plt.axis('off')
plt.show()

"""# **Spliting**"""

# TF-IDF
vectorizer = TfidfVectorizer(stop_words='english', lowercase=True)
X = vectorizer.fit_transform(Data_colect['Symptom'])
y = Data_colect['Disease']

# LabelEncoder
Encoder = LabelEncoder()
y = Encoder.fit_transform(y)

# train_test_split
x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)

y

"""# **Random Forest Classifier Model**


"""

RFC_MODEL = RandomForestClassifier(n_estimators=100, random_state=42)
RFC_MODEL.fit(x_train, y_train)
RFC_MODEL.score(x_test, y_test)

# Save the model, vectorizer, and encoder
joblib.dump(RFC_MODEL, 'disease_prediction_model.pkl')
joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')
joblib.dump(Encoder, 'label_encoder.pkl')

"""# **Model Performance Monitoring**"""

scores = cross_val_score(RFC_MODEL, X, y, cv=5)
display(scores)
print('Accuracy:', scores.mean())

y_pred = RFC_MODEL.predict(x_test)
print('pred values', y_pred[:20],'\n','True values', y_test[:20])

Report = classification_report(y_test, y_pred)
print(Report)

confusion = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(confusion, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.show()
plt.savefig('confusion_matrix DSP.png')

"""# **Building Application For Gradio**"""

def predict_disease(symptom):
    # Vectorize the input
    symptom_vectorized = vectorizer.transform([symptom])
    # Predict the disease
    prediction = RFC_MODEL.predict(symptom_vectorized)
    # Decode the prediction
    predicted_disease = Encoder.inverse_transform(prediction)[0]
    return predicted_disease

# Create the Gradio interface
iface = gr.Interface(fn=predict_disease, inputs="text", outputs="text", title="Disease Symptom Predictor", description="Enter symptoms to predict the disease.")

iface.launch()

"""# **Thank you for checking out this notebook! ❤️❤️**"""